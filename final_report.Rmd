---
title: "final report"
output: pdf_document
date: "2023-12-19"
---

# Abstract

# Introduction

# Data and Methods

## Descriptive Data

## Data Cleaning and Preparation

The dataset utilized in this study was derived from a comprehensive breast cancer database. The initial step in data preparation involved the standardization of variable names to ensure consistency. In addition, we converted several categorical variables into factors with defined levels. Specifically, we recoded the survival status variable into a binary format with `Dead` as 1 and `Alive` as 0. Finally, a new variable `node_positive_prop` was created and calculated based on the ratio of `reginol_node_positive` to `regional_node_examined`. This variable represents the proportion of examined nodes that were found to be positive.

## Variable and Model Selection Procedures

After preprocessing the dataset, we subdivided our dataset into categorical and numerical variables in order to have a general outline data patterns. In **Table 1**, we summarized the essential statistics of all the categorical variables, which includes variable names, number of missing values, unique and top counts. <br>

For numerical variables, we employed boxplot visualizations to effectively represent their distribution patterns. As illustrated in **Figure 1**, these boxplots serve as a comprehensive visualization, which include potential outliers, important quartiles, and medians of all the numerical variables. <br>

Initially, a comprehensive model incorporating all available predictors was developed, targeting survival status as the response variable. The corresponding estimates, standard errors, and P-values are illustrated in details in **Table 2**. After gaining an initial understanding of the data trends, we employed both stepwise selection and regularization techniques like LASSO and Ridge Regression for selecting the most appropriate model.<br>

In addition, we conducted a series of diagnostic evaluations on this full model. Our first step in this process was to assess multicollinearity, the results of which are presented in the Variance Inflation Factor (VIF) table depicted in **Table 3**. After the implementation of stepwise selection methods, along with LASSO and Ridge Regression, we proceeded to evaluate the classification accuracy of all the models. This was achieved through the generation of Receiver Operating Characteristic (ROC) curves and the analysis of the Area Under the Curve (AUC) statistics. The summary of all AUC statistics are included in **Table 4**. In addition, all ROC curves are illustrated with **Figure 2**, **Figure 3**, **Figure 4**, and **Figure 5**. <br>

Upon completing the process of variable selection, our analysis has yielded four distinct models, each characterized by a unique set of predictor variables. We used internal validation by splitting our dataset into traning and testing data since we couldn't collect new data to perform external validation. In addition, we used 10-fold validation to assess ability of shrinkage models(LASSO and Ridge Regression) to predict the testing data, and we referred to BIC and AIC scores when assessing the fit of backward and forward selection models. 




# Assumption Checking


# Result

## Variable Selection

Since our response variable `status` is a binary variable, we decided to implement a logistic regression in order to predict the risk of death based on variables selected. We selected our model variables in four distinct manners: two automatic approaches (both backward and forward selections) and two shrinkage methods(LASSO as well as Ridge Regression). The final models including all the variable selected by different methods are illustrated in **Table 4**, **Table 5**, **Table 6**, and **Table 7** respectively. <br>

## Model Selection
First, we closely examined the performance metrics of both backward and forward selection models, with particular emphasis on their AIC and BIC scores, as presented in **Table 8**. Our findings indicate a noticeable distinction between the two models. Specifically, the backward selection model demonstrated superior performance, if we solely assessed based on its lower AIC and BIC scores in comparison to the forward selection model.<br>

To further validate these findings, we employed 10-fold cross-validation techniques on the two automatic research approaches. This procedure yielded insightful results regarding the accuracy of each model. The backward selection model exhibited a high degree of accuracy, achieving a score of 0.858854. The forward selection model, while slightly less accurate, still maintained a high accuracy level with a score of 0.8561146.<br>

In addition, we implemented 10-fold validation on LASSO and Ridge Regression. The results are shown in 

# Conclusion

# Appendix

```{r echo=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(dplyr)
library(MASS)
library(ggplot2)
library(corrplot)
library(leaps)
library(glmnet)
library(igraph)
library(arules)
library(caret)
library(pROC)
library(performance) # vif
library(ggpubr)
library(vcd)


```


```{r echo=FALSE, warning=FALSE, message=FALSE}
# import data
breastcancer = read_csv("./data/Project_2_data.csv")

#Data Cleaning
breastcancer_1 = breastcancer|>
  janitor::clean_names()|>
   mutate(
    race = as_factor(race),
    marital_status = factor(marital_status, levels = c("Single", "Married", "Divorced", "Separated", "Widowed")),
    t_stage = factor(t_stage, levels = c("T1", "T2", "T3", "T4")),
    n_stage = factor(n_stage, levels = c("N1", "N2", "N3")),
    x6th_stage = factor(x6th_stage, levels = c("IIA", "IIB", "IIIA", "IIIB", "IIIC")),
    differentiate = factor(differentiate, levels = c("Moderately differentiated", "Poorly differentiated", "Undifferentiated", "Well differentiated")),
    grade = factor(grade, levels = c("1", "2", "3", "anaplastic; Grade IV")),
    a_stage = factor(a_stage, levels = c("Distant", "Regional")),
    estrogen_status = as_factor(estrogen_status),
    progesterone_status = as_factor(progesterone_status),
    status = ifelse(status == "Dead", 1, 0),
    status = as_factor(status))

breastcancer_clean = breastcancer_1|>
  mutate(node_positive_prop = reginol_node_positive/regional_node_examined,
         node_positive_prop = round(node_positive_prop, 4))
```


## Table

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Table 1
summary_catego =
  breastcancer_clean |>
  dplyr::select(-1, -10, -13, -14, -15) |>
  skimr::skim() |>
  dplyr::select(skim_variable, n_missing, factor.n_unique, factor.top_counts)
 
  colnames(summary_catego) = c("Variable", "Missing", "Unique Counts", "Top Counts")

knitr::kable(x = summary_catego, caption = "Summary Statistics of Categorical Variables", digits = 3)

```

```{r echo=FALSE, warning=FALSE, message=FALSE}

#split the data
set.seed(123)
breastcancer_test = breastcancer_clean|>
  dplyr::select(-survival_months)
split <- createDataPartition(breastcancer_test$status, p = .7, list = FALSE)
train_data <- breastcancer_test[split, ]
test_data <- breastcancer_test[-split, ]
test_data1 = test_data|> dplyr::select(-status)

breastcancer_clean1 <- breastcancer_test|>
  drop_na()

full_model <- glm(status ~ ., data = breastcancer_test, family = binomial())
full_model_tab = full_model|>
broom::tidy()|>
dplyr::select(term, estimate, std.error, p.value)
colnames(full_model_tab) = c("Term", "Estimate","Standard Error", "P Value")
knitr::kable(x = full_model_tab, caption = "Full Model Summary", digits = 3)


```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Calculate the variance inflation factor (VIF)
vif_full = check_collinearity(full_model)|>
  rename(CI_low = VIF_CI_low,
         CI_high = VIF_CI_high,
         Tolerance_low = Tolerance_CI_low,
         Tolerance_high = Tolerance_CI_high)|>
      as_tibble() 
knitr::kable(x = vif_full, caption = "VIF for Full Model", digits = 1)

```


```{r echo=FALSE, results = 'hide', message=FALSE, warning=FALSE}
backward_model <- step(full_model, direction = "backward")
breastcancer_for = breastcancer_test|>
  dplyr::select(-t_stage)
breastcancer_for1 = breastcancer_for|>
  dplyr::select(-x6th_stage)

null_model_2 <- glm(status ~ 1, data = breastcancer_for1, family = binomial())
full_model_2 <- glm(status ~ ., data = breastcancer_for1, family = binomial())
forward_model_2 <- step(null_model_2, scope = list(lower = null_model_2, upper = full_model_2), direction = "forward")

```


```{r echo=FALSE, results = 'hide', message=FALSE, warning=FALSE}
#split the data
set.seed(123)
breastcancer_test = breastcancer_clean|>
  dplyr::select(-survival_months)
split <- createDataPartition(breastcancer_test$status, p = .7, list = FALSE)
train_data <- breastcancer_test[split, ]
test_data <- breastcancer_test[-split, ]
X <- as.matrix(train_data[, -which(names(train_data) == "status")])
y <- train_data$status

set.seed(123)
lasso_model <- glmnet(X, y, alpha = 1, family = "binomial")

#determine the best lambda
cv_lasso <- cv.glmnet(X, y, alpha = 1, family = "binomial", type.measure = "auc")
best_lambda <- cv_lasso$lambda.min

best_coefs <- coef(cv_lasso, s = best_lambda)

```

```{r echo=FALSE, results = 'hide', message=FALSE, warning=FALSE}
set.seed(123)
ridge_model <- glmnet(X, y, alpha = 0, family = "binomial")

#determine the best lambda
cv_ridge <- cv.glmnet(X, y, alpha = 0, family = "binomial", type.measure = "auc")
best_ridge_lambda <- cv_ridge$lambda.min

best_ridge_coefs <- coef(cv_ridge, s = best_ridge_lambda)


```


```{r echo=FALSE, warning=FALSE, message=FALSE}
#table 4: AUC statistics
```


```{r echo=FALSE, warning=FALSE, message=FALSE}
backward_model_table = backward_model|>
  broom::tidy()|>
  dplyr::select(term, estimate, std.error, p.value)
colnames(backward_model_table) = c("Term", "Estimate","Standard Error", "P Value")
knitr::kable(x = backward_model_table, caption = "Backward Model Summary", digits = 3)
```



```{r echo=FALSE, warning=FALSE, message=FALSE}
forward_model_2table = forward_model_2|>
  broom::tidy()|>
  dplyr::select(term, estimate, std.error, p.value)
colnames(forward_model_2table) = c("Term", "Estimate","Standard Error", "P Value")
knitr::kable(x = forward_model_2table, caption = "Forward Model Summary", digits = 3)
```


```{r echo=FALSE, warning=FALSE, message=FALSE}
lasso_table = lasso_model|>
  broom::tidy()|>
  dplyr::select(term, estimate, lambda, dev.ratio)
colnames(lasso_table) = c("Term", "Estimate","Lambda", "Deviation Ratio")
knitr::kable(x = lasso_table, caption = "Lasso Model Summary", digits = 3)
```



```{r echo=FALSE, warning=FALSE, message=FALSE}
ridge_table = ridge_model|>
  broom::tidy()|>
  dplyr::select(term, estimate, lambda, dev.ratio)
colnames(ridge_table) = c("Term", "Estimate","Lambda", "Deviation Ratio")
knitr::kable(x = ridge_table, caption = "Ridge Regression Summary", digits = 3)
```



```{r echo=FALSE, warning=FALSE, message=FALSE}
library(tibble)
library(knitr)
aic_back = AIC(backward_model)
aic_forward = AIC(forward_model_2)
bic_back = BIC(backward_model)
bic_forward = BIC(forward_model_2)

table_9 <- cbind(aic_back,aic_forward,bic_back,bic_forward)|>
  as.tibble()
kable(x = table_9, caption = "AIC & BIC Scores for Backward and Forward Selection Model")
```


# Figure 
```{r echo=FALSE, warning=FALSE, message=FALSE}
# Figure 1
par(mfrow=c(2,3))
boxplot(breastcancer_clean$age, main='Age')
boxplot(breastcancer_clean$tumor_size, main='Tumor Size')
boxplot(breastcancer_clean$regional_node_examined,main='Node Examined' )
boxplot(breastcancer_clean$reginol_node_positive, main='Positive Node')
boxplot(breastcancer_clean$node_positive_prop, main='Proportion of Positive Nodes')
mtext("Figure 1: Numerical Variables Distribution", side = 3, line = -1.5, outer = TRUE, cex = 1.5)
```




# Contribution
